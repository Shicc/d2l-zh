{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 搞清楚fine-tuning里面的代码\n",
    "\n",
    "一些依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import d2lzh as d2l\n",
    "from mxnet import gluon, init, nd\n",
    "from mxnet.gluon import data as gdata#, loss as gloss, model_zoo\n",
    "# from mxnet.gluon import utils as gutils\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "修改data位置,有数据集就不执行这一代码块了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ../../data\\hotdog.zip from https://apache-mxnet.s3-accelerate.amazonaws.com/gluon/dataset/hotdog.zip...\n"
     ]
    }
   ],
   "source": [
    "data_dir = '../../data' ###\n",
    "base_url = 'https://apache-mxnet.s3-accelerate.amazonaws.com/'\n",
    "fname = gutils.download(\n",
    "    base_url + 'gluon/dataset/hotdog.zip',\n",
    "    path=data_dir, sha1_hash='fba480ffa8aa7e0febbb511d181409f899b9baa5')\n",
    "with zipfile.ZipFile(fname, 'r') as z:\n",
    "    z.extractall(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = gdata.vision.ImageFolderDataset(\n",
    "    os.path.join(data_dir, 'hotdog/train'))\n",
    "test_imgs = gdata.vision.ImageFolderDataset(\n",
    "    os.path.join(data_dir, 'hotdog/test'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ImageFolderDataset`是一个类，继承于`dataset.Dataset`类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mxnet.gluon.data.vision.datasets.ImageFolderDataset at 0x16157da0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 指定RGB三个通道的均值和方差来将图像通道归一化\n",
    "normalize = gdata.vision.transforms.Normalize(\n",
    "    [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "train_augs = gdata.vision.transforms.Compose([\n",
    "    gdata.vision.transforms.RandomResizedCrop(224),\n",
    "    gdata.vision.transforms.RandomFlipLeftRight(),\n",
    "    gdata.vision.transforms.ToTensor(),\n",
    "    normalize])\n",
    "\n",
    "test_augs = gdata.vision.transforms.Compose([\n",
    "    gdata.vision.transforms.Resize(256),\n",
    "    gdata.vision.transforms.CenterCrop(224),\n",
    "    gdata.vision.transforms.ToTensor(),\n",
    "    normalize])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练数据所需要的迭代器，train_iter就是一个`DataLoader`类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "train_iter = gdata.DataLoader(\n",
    "        train_imgs.transform_first(train_augs), batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train_iter`就是一个含有上面传入数据集的迭代器，里面是一个一个的batch（列表类型），包含数据和标签。其实啊，还是上面那个nb的`ImageFolderDataset`适合这样标签就是文件夹名字的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "[[[[ 0.7590547   0.7590547   0.7761795  ...  0.2281874   0.15968838\n",
      "     0.14256364]\n",
      "   [ 0.7590547   0.7590547   0.7761795  ...  0.2281874   0.15968838\n",
      "     0.14256364]\n",
      "   [ 0.72480524  0.74193     0.7761795  ...  0.2624369   0.21106265\n",
      "     0.1939379 ]\n",
      "   ...\n",
      "   [-1.5870366  -1.5699118  -1.5699118  ...  1.3412963   1.3412963\n",
      "     1.3412963 ]\n",
      "   [-1.5870366  -1.5870366  -1.5699118  ...  1.2899221   1.2727973\n",
      "     1.2727973 ]\n",
      "   [-1.5870366  -1.5870366  -1.5699118  ...  1.2899221   1.2727973\n",
      "     1.2727973 ]]\n",
      "\n",
      "  [[ 0.3452382   0.3452382   0.3627452  ... -0.24999997 -0.30252096\n",
      "    -0.30252096]\n",
      "   [ 0.3452382   0.3452382   0.3627452  ... -0.24999997 -0.30252096\n",
      "    -0.30252096]\n",
      "   [ 0.3102242   0.3102242   0.3452382  ... -0.21498597 -0.24999997\n",
      "    -0.24999997]\n",
      "   ...\n",
      "   [-1.6680672  -1.6680672  -1.6330532  ...  0.29271722  0.2752102\n",
      "     0.2577032 ]\n",
      "   [-1.6680672  -1.6680672  -1.6505601  ...  0.2752102   0.2051822\n",
      "     0.2051822 ]\n",
      "   [-1.6680672  -1.6680672  -1.6505601  ...  0.2752102   0.2226892\n",
      "     0.2051822 ]]\n",
      "\n",
      "  [[ 0.3044881   0.3044881   0.2696297  ... -0.34039208 -0.41010883\n",
      "    -0.41010883]\n",
      "   [ 0.3044881   0.3044881   0.2696297  ... -0.34039208 -0.41010883\n",
      "    -0.41010883]\n",
      "   [ 0.2696297   0.2696297   0.23477131 ... -0.32296288 -0.35782126\n",
      "    -0.35782126]\n",
      "   ...\n",
      "   [-1.4210021  -1.4210021  -1.403573   ... -0.39267966 -0.37525046\n",
      "    -0.37525046]\n",
      "   [-1.4210021  -1.4210021  -1.403573   ... -0.42753804 -0.42753804\n",
      "    -0.42753804]\n",
      "   [-1.4210021  -1.4210021  -1.403573   ... -0.42753804 -0.42753804\n",
      "    -0.42753804]]]\n",
      "\n",
      "\n",
      " [[[ 0.05693974  0.05693974  0.05693974 ...  0.69055575  0.72480524\n",
      "     0.74193   ]\n",
      "   [ 0.05693974  0.05693974  0.05693974 ...  0.673431    0.72480524\n",
      "     0.72480524]\n",
      "   [ 0.07406463  0.07406463  0.05693974 ...  0.6563062   0.69055575\n",
      "     0.69055575]\n",
      "   ...\n",
      "   [-0.13143253 -0.13143253 -0.14855729 ...  1.2556726   1.2556726\n",
      "     1.2556726 ]\n",
      "   [-0.09718303 -0.11430778 -0.13143253 ...  1.2385478   1.221423\n",
      "     1.221423  ]\n",
      "   [-0.09718303 -0.09718303 -0.13143253 ...  1.221423    1.221423\n",
      "     1.221423  ]]\n",
      "\n",
      "  [[-0.617647   -0.617647   -0.617647   ... -0.65266097 -0.60014\n",
      "    -0.60014   ]\n",
      "   [-0.617647   -0.617647   -0.617647   ... -0.670168   -0.617647\n",
      "    -0.617647  ]\n",
      "   [-0.60014    -0.60014    -0.617647   ... -0.705182   -0.670168\n",
      "    -0.670168  ]\n",
      "   ...\n",
      "   [-0.460084   -0.460084   -0.47759098 ...  0.41526622  0.41526622\n",
      "     0.41526622]\n",
      "   [-0.44257697 -0.44257697 -0.460084   ...  0.3977592   0.3977592\n",
      "     0.3802522 ]\n",
      "   [-0.44257697 -0.44257697 -0.460084   ...  0.3802522   0.3802522\n",
      "     0.3802522 ]]\n",
      "\n",
      "  [[-0.9852723  -0.9852723  -0.9852723  ... -0.776122   -0.74126357\n",
      "    -0.7238344 ]\n",
      "   [-0.9852723  -0.9852723  -0.9852723  ... -0.776122   -0.74126357\n",
      "    -0.74126357]\n",
      "   [-0.9678431  -0.9678431  -0.9852723  ... -0.79355115 -0.7586928\n",
      "    -0.7586928 ]\n",
      "   ...\n",
      "   [-0.60182995 -0.60182995 -0.6192592  ... -0.9852723  -0.9852723\n",
      "    -1.0027015 ]\n",
      "   [-0.5321132  -0.54954237 -0.5844008  ... -0.9504139  -0.9678431\n",
      "    -0.9678431 ]\n",
      "   [-0.514684   -0.514684   -0.5844008  ... -0.9329847  -0.9504139\n",
      "    -0.9504139 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.60493195  0.5878072   0.57068247 ...  0.60493195  0.5878072\n",
      "     0.5878072 ]\n",
      "   [ 0.60493195  0.5878072   0.57068247 ...  0.60493195  0.60493195\n",
      "     0.5878072 ]\n",
      "   [ 0.60493195  0.60493195  0.57068247 ...  0.6220567   0.6220567\n",
      "     0.60493195]\n",
      "   ...\n",
      "   [ 0.43368444  0.45080918  0.5193082  ... -0.9020464  -0.9020464\n",
      "    -0.91917115]\n",
      "   [ 0.43368444  0.45080918  0.5364329  ... -0.9362959  -0.95342064\n",
      "    -0.95342064]\n",
      "   [ 0.43368444  0.45080918  0.5364329  ... -0.9362959  -0.9705454\n",
      "    -0.9705454 ]]\n",
      "\n",
      "  [[-0.65266097 -0.65266097 -0.670168   ... -0.33753496 -0.35504198\n",
      "    -0.35504198]\n",
      "   [-0.65266097 -0.65266097 -0.65266097 ... -0.33753496 -0.35504198\n",
      "    -0.35504198]\n",
      "   [-0.635154   -0.635154   -0.635154   ... -0.33753496 -0.35504198\n",
      "    -0.35504198]\n",
      "   ...\n",
      "   [-0.705182   -0.687675   -0.60014    ... -1.265406   -1.265406\n",
      "    -1.265406  ]\n",
      "   [-0.705182   -0.670168   -0.582633   ... -1.247899   -1.2829131\n",
      "    -1.2829131 ]\n",
      "   [-0.687675   -0.65266097 -0.565126   ... -1.247899   -1.2829131\n",
      "    -1.2829131 ]]\n",
      "\n",
      "  [[-0.82840955 -0.82840955 -0.8109804  ... -0.34039208 -0.35782126\n",
      "    -0.35782126]\n",
      "   [-0.82840955 -0.8109804  -0.79355115 ... -0.34039208 -0.35782126\n",
      "    -0.35782126]\n",
      "   [-0.8109804  -0.79355115 -0.776122   ... -0.32296288 -0.34039208\n",
      "    -0.34039208]\n",
      "   ...\n",
      "   [-0.9504139  -0.91555554 -0.86326796 ... -1.0201306  -1.0201306\n",
      "    -1.0201306 ]\n",
      "   [-0.91555554 -0.88069713 -0.82840955 ... -1.0201306  -1.0375599\n",
      "    -1.0549891 ]\n",
      "   [-0.8981263  -0.88069713 -0.8109804  ... -1.0201306  -1.0549891\n",
      "    -1.0549891 ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 2.2317834   2.2317834   2.2489083  ... -0.9705454  -1.6041614\n",
      "    -2.0665298 ]\n",
      "   [ 2.2317834   2.2146587   2.2317834  ... -0.8335474  -1.4842881\n",
      "    -1.9637812 ]\n",
      "   [ 2.2317834   2.1975338   2.1975338  ... -0.59380084 -1.3130406\n",
      "    -1.9124069 ]\n",
      "   ...\n",
      "   [-0.4054286  -0.43967807 -0.45680285 ...  1.5981677   2.1632845\n",
      "     2.1975338 ]\n",
      "   [-0.43967807 -0.49105233 -0.4739276  ...  1.8379141   2.060536\n",
      "     2.129035  ]\n",
      "   [-0.5081771  -0.49105233 -0.45680285 ...  2.0091617   2.0262864\n",
      "     2.129035  ]]\n",
      "\n",
      "  [[ 2.3935575   2.3935575   2.4110641  ... -1.4404761  -1.8606442\n",
      "    -2.0182073 ]\n",
      "   [ 2.3935575   2.3760502   2.3935575  ... -1.317927   -1.7731092\n",
      "    -1.9831933 ]\n",
      "   [ 2.3935575   2.3935575   2.3935575  ... -1.12535    -1.6330532\n",
      "    -2.0007002 ]\n",
      "   ...\n",
      "   [-1.0728291  -1.0728291  -1.12535    ...  0.2226892   2.0084033\n",
      "     2.0259104 ]\n",
      "   [-1.0903361  -1.107843   -1.1428571  ...  1.2556022   1.9908963\n",
      "     1.9558823 ]\n",
      "   [-1.1428571  -1.160364   -1.160364   ...  1.9383754   1.8683473\n",
      "     1.8858544 ]]\n",
      "\n",
      "  [[ 2.2391288   2.2565577   2.2739873  ... -1.7172985  -1.7695861\n",
      "    -1.8044444 ]\n",
      "   [ 2.2216995   2.3088455   2.3262744  ... -1.7870152  -1.7870152\n",
      "    -1.8044444 ]\n",
      "   [ 2.2042704   2.3262744   2.343704   ... -1.8044444  -1.8044444\n",
      "    -1.7870152 ]\n",
      "   ...\n",
      "   [-1.7695861  -1.7870152  -1.7870152  ...  0.0081918   1.193377\n",
      "     1.2282355 ]\n",
      "   [-1.8044444  -1.7695861  -1.8044444  ...  0.77507645  1.0539435\n",
      "     1.0365143 ]\n",
      "   [-1.8044444  -1.7870152  -1.7870152  ...  1.193377    1.1236603\n",
      "     1.0190852 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.673431    0.673431    0.673431   ...  0.46793392  0.46793392\n",
      "     0.46793392]\n",
      "   [ 0.673431    0.673431    0.673431   ...  0.46793392  0.46793392\n",
      "     0.46793392]\n",
      "   [ 0.673431    0.673431    0.673431   ...  0.45080918  0.45080918\n",
      "     0.45080918]\n",
      "   ...\n",
      "   [-0.6622999  -0.6622999  -0.6622999  ...  0.9131775   0.9131775\n",
      "     0.9131775 ]\n",
      "   [-0.6622999  -0.6622999  -0.6622999  ...  0.9131775   0.9131775\n",
      "     0.9131775 ]\n",
      "   [-0.6622999  -0.6622999  -0.6622999  ...  0.9131775   0.9131775\n",
      "     0.9131775 ]]\n",
      "\n",
      "  [[ 0.2752102   0.2752102   0.2752102  ... -0.07492995 -0.07492995\n",
      "    -0.07492995]\n",
      "   [ 0.2752102   0.2752102   0.2752102  ... -0.07492995 -0.07492995\n",
      "    -0.07492995]\n",
      "   [ 0.2752102   0.2752102   0.2752102  ... -0.07492995 -0.07492995\n",
      "    -0.07492995]\n",
      "   ...\n",
      "   [-1.0203081  -1.0203081  -1.0203081  ...  0.50280124  0.50280124\n",
      "     0.50280124]\n",
      "   [-1.0203081  -1.0203081  -1.0203081  ...  0.50280124  0.50280124\n",
      "     0.50280124]\n",
      "   [-1.0203081  -1.0203081  -1.0203081  ...  0.50280124  0.50280124\n",
      "     0.50280124]]\n",
      "\n",
      "  [[-0.63668835 -0.63668835 -0.63668835 ... -1.4384314  -1.4384314\n",
      "    -1.4384314 ]\n",
      "   [-0.63668835 -0.63668835 -0.63668835 ... -1.4384314  -1.4384314\n",
      "    -1.4384314 ]\n",
      "   [-0.63668835 -0.63668835 -0.63668835 ... -1.4384314  -1.4384314\n",
      "    -1.4384314 ]\n",
      "   ...\n",
      "   [-1.7521569  -1.7521569  -1.7521569  ... -0.54954237 -0.54954237\n",
      "    -0.54954237]\n",
      "   [-1.7521569  -1.7521569  -1.7521569  ... -0.54954237 -0.54954237\n",
      "    -0.54954237]\n",
      "   [-1.7521569  -1.7521569  -1.7521569  ... -0.54954237 -0.54954237\n",
      "    -0.54954237]]]\n",
      "\n",
      "\n",
      " [[[ 1.5467933   1.4611696   1.5125438  ...  1.3584211   1.42692\n",
      "     1.5125438 ]\n",
      "   [ 1.3926706   1.3755459   1.4954191  ...  1.4611696   1.5296686\n",
      "     1.6495419 ]\n",
      "   [ 1.2385478   0.9816765   1.4611696  ...  1.5125438   1.3755459\n",
      "     1.5125438 ]\n",
      "   ...\n",
      "   [ 1.3584211   1.4782944   1.6495419  ...  0.27956167  0.31381115\n",
      "     0.33093593]\n",
      "   [ 1.4440448   1.4954191   1.5981677  ...  0.31381115  0.33093593\n",
      "     0.2966864 ]\n",
      "   [ 1.5467933   1.4782944   1.6324171  ...  0.33093593  0.34806067\n",
      "     0.34806067]]\n",
      "\n",
      "  [[ 0.87044823  0.88795525  0.83543426 ...  1.0105042   1.0805323\n",
      "     1.1680672 ]\n",
      "   [ 0.5903362   0.74789923  0.83543426 ...  1.1155462   1.1680672\n",
      "     1.2731093 ]\n",
      "   [ 0.3802522   0.29271722  0.87044823 ...  1.1680672   1.0105042\n",
      "     1.1155462 ]\n",
      "   ...\n",
      "   [ 0.74789923  0.88795525  0.9929972  ...  0.03011205  0.06512605\n",
      "     0.06512605]\n",
      "   [ 0.81792724  0.88795525  0.9229692  ...  0.04761905  0.08263306\n",
      "     0.08263306]\n",
      "   [ 0.94047624  0.87044823  0.95798326 ...  0.08263306  0.10014006\n",
      "     0.13515405]]\n",
      "\n",
      "  [[-1.2641394  -1.316427   -1.1595641  ...  0.09533776  0.2522005\n",
      "     0.40906325]\n",
      "   [-1.3687146  -1.403573   -1.0898474  ...  0.14762534  0.33934647\n",
      "     0.5484969 ]\n",
      "   [-1.4732897  -1.6301525  -0.7064052  ...  0.21734212  0.16505454\n",
      "     0.35677567]\n",
      "   ...\n",
      "   [-0.11381256 -0.04409578  0.0081918  ...  0.0081918   0.02562099\n",
      "     0.04305018]\n",
      "   [-0.0092374   0.0081918  -0.0092374  ...  0.02562099  0.06047938\n",
      "     0.06047938]\n",
      "   [ 0.09533776  0.02562099  0.06047938 ...  0.06047938  0.07790857\n",
      "     0.14762534]]]]\n",
      "<NDArray 128x3x224x224 @cpu(0)>] [\n",
      "[0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 1. 0.\n",
      " 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1. 1.\n",
      " 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 1.\n",
      " 1. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 0.]\n",
      "<NDArray 128 @cpu(0)>] 128\n"
     ]
    }
   ],
   "source": [
    "import mxnet as mx\n",
    "\n",
    "for i, batch in enumerate(train_iter):\n",
    "    if(i==6):\n",
    "        # 打印一个batch看看\n",
    "        batch6 = batch\n",
    "\n",
    "features, labels = batch6 # 看看\n",
    "ctx = mx.cpu(0)\n",
    "\n",
    "# 要把ctx转化成一个列表，不然求不出长度\n",
    "if isinstance(ctx, mx.Context):\n",
    "        ctx = [ctx]\n",
    "\n",
    "def get_batch(batch, ctx):\n",
    "     \"\"\"Return features and labels on ctx.\"\"\"\n",
    "     features, labels = batch   #labels是从这里来的\n",
    "     if labels.dtype != features.dtype:\n",
    "         labels = labels.astype(features.dtype)\n",
    "         return (gutils.split_and_load(features, ctx),\n",
    "                  gutils.split_and_load(labels, ctx), features.shape[0])\n",
    "\n",
    "Xs, ys, batch_size = get_batch(batch6,ctx) # 在看看这个标签\n",
    "print(Xs, ys, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "[[[[ 0.7590547   0.7590547   0.7761795  ...  0.2281874   0.15968838\n",
      "     0.14256364]\n",
      "   [ 0.7590547   0.7590547   0.7761795  ...  0.2281874   0.15968838\n",
      "     0.14256364]\n",
      "   [ 0.72480524  0.74193     0.7761795  ...  0.2624369   0.21106265\n",
      "     0.1939379 ]\n",
      "   ...\n",
      "   [-1.5870366  -1.5699118  -1.5699118  ...  1.3412963   1.3412963\n",
      "     1.3412963 ]\n",
      "   [-1.5870366  -1.5870366  -1.5699118  ...  1.2899221   1.2727973\n",
      "     1.2727973 ]\n",
      "   [-1.5870366  -1.5870366  -1.5699118  ...  1.2899221   1.2727973\n",
      "     1.2727973 ]]\n",
      "\n",
      "  [[ 0.3452382   0.3452382   0.3627452  ... -0.24999997 -0.30252096\n",
      "    -0.30252096]\n",
      "   [ 0.3452382   0.3452382   0.3627452  ... -0.24999997 -0.30252096\n",
      "    -0.30252096]\n",
      "   [ 0.3102242   0.3102242   0.3452382  ... -0.21498597 -0.24999997\n",
      "    -0.24999997]\n",
      "   ...\n",
      "   [-1.6680672  -1.6680672  -1.6330532  ...  0.29271722  0.2752102\n",
      "     0.2577032 ]\n",
      "   [-1.6680672  -1.6680672  -1.6505601  ...  0.2752102   0.2051822\n",
      "     0.2051822 ]\n",
      "   [-1.6680672  -1.6680672  -1.6505601  ...  0.2752102   0.2226892\n",
      "     0.2051822 ]]\n",
      "\n",
      "  [[ 0.3044881   0.3044881   0.2696297  ... -0.34039208 -0.41010883\n",
      "    -0.41010883]\n",
      "   [ 0.3044881   0.3044881   0.2696297  ... -0.34039208 -0.41010883\n",
      "    -0.41010883]\n",
      "   [ 0.2696297   0.2696297   0.23477131 ... -0.32296288 -0.35782126\n",
      "    -0.35782126]\n",
      "   ...\n",
      "   [-1.4210021  -1.4210021  -1.403573   ... -0.39267966 -0.37525046\n",
      "    -0.37525046]\n",
      "   [-1.4210021  -1.4210021  -1.403573   ... -0.42753804 -0.42753804\n",
      "    -0.42753804]\n",
      "   [-1.4210021  -1.4210021  -1.403573   ... -0.42753804 -0.42753804\n",
      "    -0.42753804]]]\n",
      "\n",
      "\n",
      " [[[ 0.05693974  0.05693974  0.05693974 ...  0.69055575  0.72480524\n",
      "     0.74193   ]\n",
      "   [ 0.05693974  0.05693974  0.05693974 ...  0.673431    0.72480524\n",
      "     0.72480524]\n",
      "   [ 0.07406463  0.07406463  0.05693974 ...  0.6563062   0.69055575\n",
      "     0.69055575]\n",
      "   ...\n",
      "   [-0.13143253 -0.13143253 -0.14855729 ...  1.2556726   1.2556726\n",
      "     1.2556726 ]\n",
      "   [-0.09718303 -0.11430778 -0.13143253 ...  1.2385478   1.221423\n",
      "     1.221423  ]\n",
      "   [-0.09718303 -0.09718303 -0.13143253 ...  1.221423    1.221423\n",
      "     1.221423  ]]\n",
      "\n",
      "  [[-0.617647   -0.617647   -0.617647   ... -0.65266097 -0.60014\n",
      "    -0.60014   ]\n",
      "   [-0.617647   -0.617647   -0.617647   ... -0.670168   -0.617647\n",
      "    -0.617647  ]\n",
      "   [-0.60014    -0.60014    -0.617647   ... -0.705182   -0.670168\n",
      "    -0.670168  ]\n",
      "   ...\n",
      "   [-0.460084   -0.460084   -0.47759098 ...  0.41526622  0.41526622\n",
      "     0.41526622]\n",
      "   [-0.44257697 -0.44257697 -0.460084   ...  0.3977592   0.3977592\n",
      "     0.3802522 ]\n",
      "   [-0.44257697 -0.44257697 -0.460084   ...  0.3802522   0.3802522\n",
      "     0.3802522 ]]\n",
      "\n",
      "  [[-0.9852723  -0.9852723  -0.9852723  ... -0.776122   -0.74126357\n",
      "    -0.7238344 ]\n",
      "   [-0.9852723  -0.9852723  -0.9852723  ... -0.776122   -0.74126357\n",
      "    -0.74126357]\n",
      "   [-0.9678431  -0.9678431  -0.9852723  ... -0.79355115 -0.7586928\n",
      "    -0.7586928 ]\n",
      "   ...\n",
      "   [-0.60182995 -0.60182995 -0.6192592  ... -0.9852723  -0.9852723\n",
      "    -1.0027015 ]\n",
      "   [-0.5321132  -0.54954237 -0.5844008  ... -0.9504139  -0.9678431\n",
      "    -0.9678431 ]\n",
      "   [-0.514684   -0.514684   -0.5844008  ... -0.9329847  -0.9504139\n",
      "    -0.9504139 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.60493195  0.5878072   0.57068247 ...  0.60493195  0.5878072\n",
      "     0.5878072 ]\n",
      "   [ 0.60493195  0.5878072   0.57068247 ...  0.60493195  0.60493195\n",
      "     0.5878072 ]\n",
      "   [ 0.60493195  0.60493195  0.57068247 ...  0.6220567   0.6220567\n",
      "     0.60493195]\n",
      "   ...\n",
      "   [ 0.43368444  0.45080918  0.5193082  ... -0.9020464  -0.9020464\n",
      "    -0.91917115]\n",
      "   [ 0.43368444  0.45080918  0.5364329  ... -0.9362959  -0.95342064\n",
      "    -0.95342064]\n",
      "   [ 0.43368444  0.45080918  0.5364329  ... -0.9362959  -0.9705454\n",
      "    -0.9705454 ]]\n",
      "\n",
      "  [[-0.65266097 -0.65266097 -0.670168   ... -0.33753496 -0.35504198\n",
      "    -0.35504198]\n",
      "   [-0.65266097 -0.65266097 -0.65266097 ... -0.33753496 -0.35504198\n",
      "    -0.35504198]\n",
      "   [-0.635154   -0.635154   -0.635154   ... -0.33753496 -0.35504198\n",
      "    -0.35504198]\n",
      "   ...\n",
      "   [-0.705182   -0.687675   -0.60014    ... -1.265406   -1.265406\n",
      "    -1.265406  ]\n",
      "   [-0.705182   -0.670168   -0.582633   ... -1.247899   -1.2829131\n",
      "    -1.2829131 ]\n",
      "   [-0.687675   -0.65266097 -0.565126   ... -1.247899   -1.2829131\n",
      "    -1.2829131 ]]\n",
      "\n",
      "  [[-0.82840955 -0.82840955 -0.8109804  ... -0.34039208 -0.35782126\n",
      "    -0.35782126]\n",
      "   [-0.82840955 -0.8109804  -0.79355115 ... -0.34039208 -0.35782126\n",
      "    -0.35782126]\n",
      "   [-0.8109804  -0.79355115 -0.776122   ... -0.32296288 -0.34039208\n",
      "    -0.34039208]\n",
      "   ...\n",
      "   [-0.9504139  -0.91555554 -0.86326796 ... -1.0201306  -1.0201306\n",
      "    -1.0201306 ]\n",
      "   [-0.91555554 -0.88069713 -0.82840955 ... -1.0201306  -1.0375599\n",
      "    -1.0549891 ]\n",
      "   [-0.8981263  -0.88069713 -0.8109804  ... -1.0201306  -1.0549891\n",
      "    -1.0549891 ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 2.2317834   2.2317834   2.2489083  ... -0.9705454  -1.6041614\n",
      "    -2.0665298 ]\n",
      "   [ 2.2317834   2.2146587   2.2317834  ... -0.8335474  -1.4842881\n",
      "    -1.9637812 ]\n",
      "   [ 2.2317834   2.1975338   2.1975338  ... -0.59380084 -1.3130406\n",
      "    -1.9124069 ]\n",
      "   ...\n",
      "   [-0.4054286  -0.43967807 -0.45680285 ...  1.5981677   2.1632845\n",
      "     2.1975338 ]\n",
      "   [-0.43967807 -0.49105233 -0.4739276  ...  1.8379141   2.060536\n",
      "     2.129035  ]\n",
      "   [-0.5081771  -0.49105233 -0.45680285 ...  2.0091617   2.0262864\n",
      "     2.129035  ]]\n",
      "\n",
      "  [[ 2.3935575   2.3935575   2.4110641  ... -1.4404761  -1.8606442\n",
      "    -2.0182073 ]\n",
      "   [ 2.3935575   2.3760502   2.3935575  ... -1.317927   -1.7731092\n",
      "    -1.9831933 ]\n",
      "   [ 2.3935575   2.3935575   2.3935575  ... -1.12535    -1.6330532\n",
      "    -2.0007002 ]\n",
      "   ...\n",
      "   [-1.0728291  -1.0728291  -1.12535    ...  0.2226892   2.0084033\n",
      "     2.0259104 ]\n",
      "   [-1.0903361  -1.107843   -1.1428571  ...  1.2556022   1.9908963\n",
      "     1.9558823 ]\n",
      "   [-1.1428571  -1.160364   -1.160364   ...  1.9383754   1.8683473\n",
      "     1.8858544 ]]\n",
      "\n",
      "  [[ 2.2391288   2.2565577   2.2739873  ... -1.7172985  -1.7695861\n",
      "    -1.8044444 ]\n",
      "   [ 2.2216995   2.3088455   2.3262744  ... -1.7870152  -1.7870152\n",
      "    -1.8044444 ]\n",
      "   [ 2.2042704   2.3262744   2.343704   ... -1.8044444  -1.8044444\n",
      "    -1.7870152 ]\n",
      "   ...\n",
      "   [-1.7695861  -1.7870152  -1.7870152  ...  0.0081918   1.193377\n",
      "     1.2282355 ]\n",
      "   [-1.8044444  -1.7695861  -1.8044444  ...  0.77507645  1.0539435\n",
      "     1.0365143 ]\n",
      "   [-1.8044444  -1.7870152  -1.7870152  ...  1.193377    1.1236603\n",
      "     1.0190852 ]]]\n",
      "\n",
      "\n",
      " [[[ 0.673431    0.673431    0.673431   ...  0.46793392  0.46793392\n",
      "     0.46793392]\n",
      "   [ 0.673431    0.673431    0.673431   ...  0.46793392  0.46793392\n",
      "     0.46793392]\n",
      "   [ 0.673431    0.673431    0.673431   ...  0.45080918  0.45080918\n",
      "     0.45080918]\n",
      "   ...\n",
      "   [-0.6622999  -0.6622999  -0.6622999  ...  0.9131775   0.9131775\n",
      "     0.9131775 ]\n",
      "   [-0.6622999  -0.6622999  -0.6622999  ...  0.9131775   0.9131775\n",
      "     0.9131775 ]\n",
      "   [-0.6622999  -0.6622999  -0.6622999  ...  0.9131775   0.9131775\n",
      "     0.9131775 ]]\n",
      "\n",
      "  [[ 0.2752102   0.2752102   0.2752102  ... -0.07492995 -0.07492995\n",
      "    -0.07492995]\n",
      "   [ 0.2752102   0.2752102   0.2752102  ... -0.07492995 -0.07492995\n",
      "    -0.07492995]\n",
      "   [ 0.2752102   0.2752102   0.2752102  ... -0.07492995 -0.07492995\n",
      "    -0.07492995]\n",
      "   ...\n",
      "   [-1.0203081  -1.0203081  -1.0203081  ...  0.50280124  0.50280124\n",
      "     0.50280124]\n",
      "   [-1.0203081  -1.0203081  -1.0203081  ...  0.50280124  0.50280124\n",
      "     0.50280124]\n",
      "   [-1.0203081  -1.0203081  -1.0203081  ...  0.50280124  0.50280124\n",
      "     0.50280124]]\n",
      "\n",
      "  [[-0.63668835 -0.63668835 -0.63668835 ... -1.4384314  -1.4384314\n",
      "    -1.4384314 ]\n",
      "   [-0.63668835 -0.63668835 -0.63668835 ... -1.4384314  -1.4384314\n",
      "    -1.4384314 ]\n",
      "   [-0.63668835 -0.63668835 -0.63668835 ... -1.4384314  -1.4384314\n",
      "    -1.4384314 ]\n",
      "   ...\n",
      "   [-1.7521569  -1.7521569  -1.7521569  ... -0.54954237 -0.54954237\n",
      "    -0.54954237]\n",
      "   [-1.7521569  -1.7521569  -1.7521569  ... -0.54954237 -0.54954237\n",
      "    -0.54954237]\n",
      "   [-1.7521569  -1.7521569  -1.7521569  ... -0.54954237 -0.54954237\n",
      "    -0.54954237]]]\n",
      "\n",
      "\n",
      " [[[ 1.5467933   1.4611696   1.5125438  ...  1.3584211   1.42692\n",
      "     1.5125438 ]\n",
      "   [ 1.3926706   1.3755459   1.4954191  ...  1.4611696   1.5296686\n",
      "     1.6495419 ]\n",
      "   [ 1.2385478   0.9816765   1.4611696  ...  1.5125438   1.3755459\n",
      "     1.5125438 ]\n",
      "   ...\n",
      "   [ 1.3584211   1.4782944   1.6495419  ...  0.27956167  0.31381115\n",
      "     0.33093593]\n",
      "   [ 1.4440448   1.4954191   1.5981677  ...  0.31381115  0.33093593\n",
      "     0.2966864 ]\n",
      "   [ 1.5467933   1.4782944   1.6324171  ...  0.33093593  0.34806067\n",
      "     0.34806067]]\n",
      "\n",
      "  [[ 0.87044823  0.88795525  0.83543426 ...  1.0105042   1.0805323\n",
      "     1.1680672 ]\n",
      "   [ 0.5903362   0.74789923  0.83543426 ...  1.1155462   1.1680672\n",
      "     1.2731093 ]\n",
      "   [ 0.3802522   0.29271722  0.87044823 ...  1.1680672   1.0105042\n",
      "     1.1155462 ]\n",
      "   ...\n",
      "   [ 0.74789923  0.88795525  0.9929972  ...  0.03011205  0.06512605\n",
      "     0.06512605]\n",
      "   [ 0.81792724  0.88795525  0.9229692  ...  0.04761905  0.08263306\n",
      "     0.08263306]\n",
      "   [ 0.94047624  0.87044823  0.95798326 ...  0.08263306  0.10014006\n",
      "     0.13515405]]\n",
      "\n",
      "  [[-1.2641394  -1.316427   -1.1595641  ...  0.09533776  0.2522005\n",
      "     0.40906325]\n",
      "   [-1.3687146  -1.403573   -1.0898474  ...  0.14762534  0.33934647\n",
      "     0.5484969 ]\n",
      "   [-1.4732897  -1.6301525  -0.7064052  ...  0.21734212  0.16505454\n",
      "     0.35677567]\n",
      "   ...\n",
      "   [-0.11381256 -0.04409578  0.0081918  ...  0.0081918   0.02562099\n",
      "     0.04305018]\n",
      "   [-0.0092374   0.0081918  -0.0092374  ...  0.02562099  0.06047938\n",
      "     0.06047938]\n",
      "   [ 0.09533776  0.02562099  0.06047938 ...  0.06047938  0.07790857\n",
      "     0.14762534]]]]\n",
      "<NDArray 128x3x224x224 @cpu(0)>, \n",
      "[0 1 0 1 0 1 0 1 0 1 0 1 1 1 1 1 0 0 1 0 0 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0\n",
      " 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 0 1 1 1 0 1 0 0 1 1 1 0 1 1 0 0\n",
      " 1 1 0 0 1 0 0 0 1 1 1 1 1 0 1 0 0 1 0 1 0 1 1 0 1 1 0 0 0 1 1 1 1 0 0 1 0\n",
      " 0 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0]\n",
      "<NDArray 128 @cpu(0)>]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# 看看batch是什么东西\n",
    "print(batch6)\n",
    "print(type(batch6)) #就是一个list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mxnet.gluon.data.dataloader.DataLoader at 0xe94bda0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`batch_size`设置的128，一共2000个样本，故一共有15.625个批次，这里取16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_iter.__len__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在`d2l.train()`函数里，有一句是`for i, batch in enumerate(train_iter)`，就是从这个迭代器里取出一批一批的数据，下面是一些d2l里的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading C:\\Users\\shi\\AppData\\Roaming\\mxnet\\models\\resnet152_v2-f2695542.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/resnet152_v2-f2695542.zip...\n"
     ]
    }
   ],
   "source": [
    "# 看看resnet152多大，230mb\n",
    "pretrained_net = model_zoo.vision.resnet152_v2(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetV2(\n",
       "  (features): HybridSequential(\n",
       "    (0): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=True, use_global_stats=False, in_channels=3)\n",
       "    (1): Conv2D(3 -> 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
       "    (3): Activation(relu)\n",
       "    (4): MaxPool2D(size=(3, 3), stride=(2, 2), padding=(1, 1), ceil_mode=False)\n",
       "    (5): HybridSequential(\n",
       "      (0): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
       "        (conv1): Conv2D(64 -> 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
       "        (conv2): Conv2D(64 -> 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
       "        (conv3): Conv2D(64 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (downsample): Conv2D(64 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (1): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv1): Conv2D(256 -> 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
       "        (conv2): Conv2D(64 -> 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
       "        (conv3): Conv2D(64 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv1): Conv2D(256 -> 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
       "        (conv2): Conv2D(64 -> 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=64)\n",
       "        (conv3): Conv2D(64 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (6): HybridSequential(\n",
       "      (0): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv1): Conv2D(256 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
       "        (conv2): Conv2D(128 -> 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
       "        (conv3): Conv2D(128 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (downsample): Conv2D(256 -> 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "      (1): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
       "        (conv1): Conv2D(512 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
       "        (conv2): Conv2D(128 -> 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
       "        (conv3): Conv2D(128 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
       "        (conv1): Conv2D(512 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
       "        (conv2): Conv2D(128 -> 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
       "        (conv3): Conv2D(128 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (3): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
       "        (conv1): Conv2D(512 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
       "        (conv2): Conv2D(128 -> 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
       "        (conv3): Conv2D(128 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (4): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
       "        (conv1): Conv2D(512 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
       "        (conv2): Conv2D(128 -> 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
       "        (conv3): Conv2D(128 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (5): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
       "        (conv1): Conv2D(512 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
       "        (conv2): Conv2D(128 -> 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
       "        (conv3): Conv2D(128 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (6): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
       "        (conv1): Conv2D(512 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
       "        (conv2): Conv2D(128 -> 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
       "        (conv3): Conv2D(128 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (7): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
       "        (conv1): Conv2D(512 -> 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
       "        (conv2): Conv2D(128 -> 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=128)\n",
       "        (conv3): Conv2D(128 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (7): HybridSequential(\n",
       "      (0): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
       "        (conv1): Conv2D(512 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (downsample): Conv2D(512 -> 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "      (1): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (3): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (4): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (5): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (6): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (7): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (8): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (9): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (10): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (11): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (12): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (13): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (14): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (15): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (16): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (17): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (18): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (19): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (20): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (21): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (22): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (23): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (24): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (25): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (26): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (27): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (28): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (29): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (30): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (31): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (32): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (33): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (34): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (35): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        (conv1): Conv2D(1024 -> 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv2): Conv2D(256 -> 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=256)\n",
       "        (conv3): Conv2D(256 -> 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (8): HybridSequential(\n",
       "      (0): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=1024)\n",
       "        (conv1): Conv2D(1024 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
       "        (conv2): Conv2D(512 -> 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
       "        (conv3): Conv2D(512 -> 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (downsample): Conv2D(1024 -> 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "      )\n",
       "      (1): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
       "        (conv1): Conv2D(2048 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
       "        (conv2): Conv2D(512 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
       "        (conv3): Conv2D(512 -> 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (2): BottleneckV2(\n",
       "        (bn1): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
       "        (conv1): Conv2D(2048 -> 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
       "        (conv2): Conv2D(512 -> 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=512)\n",
       "        (conv3): Conv2D(512 -> 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (9): BatchNorm(axis=1, eps=1e-05, momentum=0.9, fix_gamma=False, use_global_stats=False, in_channels=2048)\n",
       "    (10): Activation(relu)\n",
       "    (11): GlobalAvgPool2D(size=(1, 1), stride=(1, 1), padding=(0, 0), ceil_mode=True)\n",
       "    (12): Flatten\n",
       "  )\n",
       "  (output): Dense(2048 -> 1000, linear)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dense(2048 -> 1000, linear)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_net.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
